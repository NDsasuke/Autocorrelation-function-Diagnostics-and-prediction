{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDibQfVe6OtUFT764j21BP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NDsasuke/Autocorrelation-function-Diagnostics-and-prediction/blob/main/Diagnostics%20and%20prediction/Cross-Validation/Leave_One_Out_Cross_Validation_(LOOCV).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Importing Libraries**: This segment imports the necessary libraries and modules required for the code, including `numpy`, `sklearn.model_selection.LeaveOneOut`, `sklearn.linear_model.LogisticRegression`, `sklearn.datasets.load_iris`, and `warnings`.\n"
      ],
      "metadata": {
        "id": "Je-m0d-v80Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "import warnings"
      ],
      "metadata": {
        "id": "4QpWSAN-9UqI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. **Loading the Iris Dataset**: This segment loads the Iris dataset using the `load_iris()` function from `sklearn.datasets` module. The dataset contains samples of iris flowers and their corresponding target labels.\n"
      ],
      "metadata": {
        "id": "qyyAdZBn84Hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n"
      ],
      "metadata": {
        "id": "ymNM8mZU9Wpl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. **Creating a LeaveOneOut Object**: Here, we create a `LeaveOneOut` object named `loo` using the `LeaveOneOut()` class from `sklearn.model_selection`. This object implements the Leave-One-Out Cross-Validation technique.\n"
      ],
      "metadata": {
        "id": "YZ5eatUF87Lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a LeaveOneOut object\n",
        "loo = LeaveOneOut()\n"
      ],
      "metadata": {
        "id": "F3xEElen9ZFR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "4. **Initializing Evaluation Metrics List**: We initialize an empty list `scores` that will be used to store the evaluation metric (accuracy) for each iteration of the cross-validation.\n"
      ],
      "metadata": {
        "id": "1jVnrjkc8-jT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to store the evaluation metrics for each iteration\n",
        "scores = []\n"
      ],
      "metadata": {
        "id": "tYaE2X5G9cTw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "5. **Performing Leave-One-Out Cross-Validation**: This segment starts a `for` loop to iterate over the training and test indices generated by the `loo.split(X)` method. The `split()` method splits the data into training and test sets for each iteration.\n"
      ],
      "metadata": {
        "id": "LHEgo5md9Bi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "6. **Splitting Data and Training the Model**: Inside the loop, we split the data into training and test sets based on the indices obtained from `loo.split(X)`. This ensures that in each iteration, one sample is held out as the test set, while the rest are used for training. We assign the corresponding features and target values to `X_train`, `X_test`, `y_train`, and `y_test`.\n"
      ],
      "metadata": {
        "id": "-B1txMGM9EAw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "7. **Training the Logistic Regression Model**: We create a `LogisticRegression` model object named `model` and fit it to the training data (`X_train`, `y_train`) using the `fit()` method.\n"
      ],
      "metadata": {
        "id": "HJI7cmUr9Gx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "8. **Evaluating the Model**: We use the `score()` method to evaluate the trained model on the test data (`X_test`, `y_test`) and obtain the accuracy score for the current iteration. The accuracy score represents the fraction of correctly classified samples.\n"
      ],
      "metadata": {
        "id": "6eUW0CMO9Iui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "9. **Storing the Evaluation Metric**: The obtained accuracy score is appended to the `scores` list, which keeps track of the evaluation metric for each iteration.\n"
      ],
      "metadata": {
        "id": "JWgPSjJB9Khn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Leave-One-Out Cross-Validation\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "    for train_index, test_index in loo.split(X):\n",
        "        # Split the data into training and test sets for the current iteration\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Train the model on the training data\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate the model on the test data and store the score\n",
        "        score = model.score(X_test, y_test)\n",
        "        scores.append(score)\n"
      ],
      "metadata": {
        "id": "G-t8j4vg9fwT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "10. **Calculating the Average Accuracy**: After completing all the iterations, we calculate the average accuracy by taking the mean of all the scores in the `scores` list using `np.mean()`.\n"
      ],
      "metadata": {
        "id": "v0mlwnI-9MbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = np.mean(scores)\n"
      ],
      "metadata": {
        "id": "MDHSRDHm9pgL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "11. **Printing the Accuracy**: Finally, we print the average accuracy score obtained from the Leave-One-Out Cross-Validation.\n"
      ],
      "metadata": {
        "id": "RiBocMh19O3M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga-_23YS7JGs",
        "outputId": "f449abb9-025e-4f85-d6e2-c4e538b7a2af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9666666666666667\n"
          ]
        }
      ],
      "source": [
        "# Print the accuracy\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ]
    }
  ]
}